{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286f1461",
   "metadata": {},
   "source": [
    "- $p$ es el orden (número de lags temporales) de la parte autorregresiva del modelo.\n",
    "\n",
    "- $d$ es el grado de diferenciación (el número de veces que se han restado los valores consecutivos de la serie).\n",
    "\n",
    "- $q$ es el tamaño de la media móvil del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996c057",
   "metadata": {},
   "source": [
    "- $P$ es el orden (número de lags temporales) de la parte estacional del modelo.\n",
    "\n",
    "- $D$ es el grado de diferenciación de la parte estacional del modelo.\n",
    "\n",
    "- $Q$ es el tamaño de la media móvil de la parte estacional del modelo.\n",
    "\n",
    "- $m$ indica al número de períodos en cada temporada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda0fc8",
   "metadata": {},
   "source": [
    "# Librerías utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab130a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_column_indices' from 'sklearn.utils' (c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_dataset\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sarimax\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mForecasterSarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterSarimax\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection_sarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backtesting_sarimax\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection_sarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grid_search_sarimax\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skforecast\\ForecasterSarimax\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mForecasterSarimax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForecasterSarimax\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skforecast\\ForecasterSarimax\\ForecasterSarimax.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IgnoredArgumentWarning\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_select_fit_kwargs\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_y\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_exog\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skforecast\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skforecast\\utils\\utils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskforecast\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Meta-estimators for building composite models with transformers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mIn addition to its current contents, this module will eventually be home to\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mrefurbished versions of Pipeline and FeatureUnion.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_column_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ColumnTransformer,\n\u001b[0;32m     10\u001b[0m     make_column_selector,\n\u001b[0;32m     11\u001b[0m     make_column_transformer,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_target\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformedTargetRegressor\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_column_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformedTargetRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_column_selector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fit_transform_one, _name_estimators, _transform_one\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, _get_column_indices, _safe_indexing\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VisualBlock\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m METHODS\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_get_column_indices' from 'sklearn.utils' (c:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "# ======================================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# pmdarima\n",
    "from pmdarima import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# statsmodels\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# skforecast\n",
    "import skforecast\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.Sarimax import Sarimax\n",
    "from skforecast.ForecasterSarimax import ForecasterSarimax\n",
    "from skforecast.model_selection_sarimax import backtesting_sarimax\n",
    "from skforecast.model_selection_sarimax import grid_search_sarimax\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "print('Skforecast version: ', skforecast.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e01875",
   "metadata": {},
   "source": [
    "# Datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b100a3a",
   "metadata": {},
   "source": [
    "Los datos son del consumo mensual de combustible en España"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga datos\n",
    "# ======================================================================================\n",
    "url = (\n",
    "    'https://raw.githubusercontent.com/JoaquinAmatRodrigo/Estadistica-machine-learning-python/'\n",
    "    'master/data/consumos-combustibles-mensual.csv'\n",
    ")\n",
    "datos = pd.read_csv(url, sep=',')\n",
    "datos = datos[['Fecha', 'Gasolinas']]\n",
    "datos = datos.rename(columns={'Fecha':'date', 'Gasolinas':'litters'})\n",
    "datos['date'] = pd.to_datetime(datos['date'], format='%Y-%m-%d')\n",
    "datos = datos.set_index('date')\n",
    "datos = datos.loc[:'1990-01-01 00:00:00']\n",
    "datos = datos.asfreq('MS')\n",
    "datos = datos['litters']\n",
    "display(datos.head(4))\n",
    "\n",
    "# Fechas Train-test\n",
    "# ======================================================================================\n",
    "fin_train = '1980-01-01 23:59:59'\n",
    "print(f\"Fechas train : {datos.index.min()} --- {datos.loc[:fin_train].index.max()}  (n={len(datos.loc[:fin_train])})\")\n",
    "print(f\"Fechas test  : {datos.loc[fin_train:].index.min()} --- {datos.loc[:].index.max()}  (n={len(datos.loc[fin_train:])})\")\n",
    "datos_train = datos.loc[:fin_train]\n",
    "datos_test  = datos.loc[fin_train:]\n",
    "\n",
    "# Gráfico\n",
    "# ======================================================================================\n",
    "fig, ax=plt.subplots(figsize=(7, 3))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "ax.set_title('Consumo mensual combustible España')\n",
    "ax.legend();\n",
    "plt.savefig('serieDividida.png', dpi=300)\n",
    "\n",
    "# Gráfico2\n",
    "# ======================================================================================\n",
    "fig, ax=plt.subplots(figsize=(7, 3))\n",
    "datos.plot(ax=ax, label='Datos')\n",
    "ax.set_title('Consumo mensual combustible España')\n",
    "ax.legend();\n",
    "# plt.savefig('serieORIGINAL.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998d88b",
   "metadata": {},
   "source": [
    "Podemos ver como ya se han separado los datos entre el set de entrenamiento y el de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c322ea3",
   "metadata": {},
   "source": [
    "# Análisis exploratorio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd67d67",
   "metadata": {},
   "source": [
    "Crear un modelo ARIMA requiere de un análisis exploratorio de los datos exhaustivo,  esto sirve para ver el comportamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438a10e",
   "metadata": {},
   "source": [
    "Antes de entrenar un modelo ARIMA a una serie temporal, es importante realizar un análisis exploratorio para determinar, como mínimo, lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22488147",
   "metadata": {},
   "source": [
    "- Estacionariedad: la estacionariedad significa que las propiedades estadísticas (media, varianza...) permanecen constantes a lo largo del tiempo, por lo que las series temporales con tendencias o estacionalidad no son estacionarias. Dado que ARIMA presupone la estacionariedad de los datos, es esencial someterlos a pruebas rigurosas, como la prueba Dickey-Fuller aumentada, para evaluar que se cumple. Si se constata la no estacionariedad, las series deben diferenciarse hasta alcanzar la estacionariedad. Este análisis ayuda a determinar el valor óptimo del parámetro **$d$**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f6cefb",
   "metadata": {},
   "source": [
    "- Análisis de autocorrelación: Graficar las funciones de autocorrelación y autocorrelación parcial (ACF y PACF) para identificar posibles relaciones de rezago (lags) entre los valores de la serie. Este análisis visual ayuda a determinar los términos autorregresivos (AR) y de media móvil (MA) adecuados (**$p$** y  **$q$**) para el modelo ARIMA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d925e",
   "metadata": {},
   "source": [
    "- Descomposición estacional: en los casos donde se sospecha de estacionalidad, descomponer la serie en componentes de tendencia, estacionales y residuales utilizando técnicas como las medias móviles la descomposición estacional de series temporales (STL) puede revelar patrones ocultos y ayudar a identificar la estacionalidad. Este análisis ayuda a determinar los valores óptimos de los parámetros  **$P$**, **$D$**, **$Q$** y  **$m$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f78d2",
   "metadata": {},
   "source": [
    "# Estacionariedad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c381b",
   "metadata": {},
   "source": [
    "Existen varios métodos para evaluar si una serie temporal es estacionaria o no estacionaria:\n",
    "\n",
    "- Inspección Visual: Viendo el gráfico de la serie de tiempo, se pueden reconocer tendencias o estacinonalidades notables, sino, lo más probable es que la serie no sea estacionaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36d633",
   "metadata": {},
   "source": [
    "- Valores estadísticos: calcular estadísticos como la media y la varianza, de varios segmentos de la serie. Si existen diferencias significativas, la serie no es estacionaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71773a3e",
   "metadata": {},
   "source": [
    "- Pruebas estadísticas: utilizar test estadísticos como la prueba Dickey-Fuller aumentada o la prueba Kwiatkowski-Phillips-Schmidt-Shin (KPSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb8210",
   "metadata": {},
   "source": [
    "La diferenciación es una de las técnicas más sencillas para eliminar la tendencia de una serie temporal. Consiste en generar una nueva serie en la que cada valor se calcula como la diferencia entre el valor actual y el valor anterior, es decir, la diferencia entre valores consecutivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247def7e",
   "metadata": {},
   "source": [
    "El gráfico generado en el apartado anterior muestra una clara tendencia positiva, lo que indica un aumento constante a lo largo del tiempo. En consecuencia, la media de la serie aumenta con el tiempo, lo que confirma su no estacionariedad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157a8f0",
   "metadata": {},
   "source": [
    "# Prueba de Dickey-Fuller aumentada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193cb52",
   "metadata": {},
   "source": [
    "Esta prueba considera como hipótesis nula que la serie de tiempo **NO** es estacionaria(tiene una raíz unitaria). Por el contrario, la hipótesis alternativa (bajo la cual se rechaza la hipótesis nula) es que la serie es estacionaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49265f6e",
   "metadata": {},
   "source": [
    "Así, tendremos que:\n",
    "\n",
    "-$H_{O}$: La serie no es estacionaria (tiene una raíz unitaria).\n",
    "\n",
    "-$H_{A}$: La serie es estacionaria ( **no** tiene una raíz unitaria)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43eb235",
   "metadata": {},
   "source": [
    "Dado que la hipótesis nula supone la presencia de una raíz unitaria, el p-value obtenido debe ser inferior a un nivel de significación determinado, a menudo fijado en 0.05, para rechazar esta hipótesis. \n",
    "\n",
    "\n",
    "Este resultado indica la estacionariedad de la serie. Su resultado incluye cuatro valores: el p-value, el valor del estadístico, el número de retardos (lags) incluidos en la prueba y los umbrales del valor crítico para tres niveles diferentes de significancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be459",
   "metadata": {},
   "source": [
    "# Prueba Kwiatkowski-Phillips-Schmidt-Shin (KPSS).\n",
    "\n",
    "La prueba KPSS comprueba si una serie de tiempo es estacionaria en torno a una media o una tendencia lineal. En esta prueba, la hipótesis nula es que la serie es estacionaria. Por lo tanto, los p-values pequeños (por ejemplo, inferiores a 0.05) rechazan la hipótesis nula y sugieren que es necesario diferenciar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test estacionariedad\n",
    "# ==============================================================================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "datos_diff_1 = datos_train.diff().dropna()\n",
    "datos_diff_2 = datos_diff_1.diff().dropna()\n",
    "\n",
    "print('Test estacionariedad serie original')\n",
    "print('-------------------------------------')\n",
    "adfuller_result = adfuller(datos)\n",
    "kpss_result = kpss(datos)\n",
    "print(f'ADF Statistic: {adfuller_result[0]}, p-value: {adfuller_result[1]}')\n",
    "print(f'KPSS Statistic: {kpss_result[0]}, p-value: {kpss_result[1]}')\n",
    "\n",
    "print('\\nTest estacionariedad para serie diferenciada (order=1)')\n",
    "print('--------------------------------------------------')\n",
    "adfuller_result = adfuller(datos_diff_1)\n",
    "kpss_result = kpss(datos.diff().dropna())\n",
    "print(f'ADF Statistic: {adfuller_result[0]}, p-value: {adfuller_result[1]}')\n",
    "print(f'KPSS Statistic: {kpss_result[0]}, p-value: {kpss_result[1]}')\n",
    "\n",
    "print('\\nTest estacionariedad para serie diferenciada (order=2)')\n",
    "print('--------------------------------------------------')\n",
    "adfuller_result = adfuller(datos_diff_2)\n",
    "kpss_result = kpss(datos.diff().diff().dropna())\n",
    "print(f'ADF Statistic: {adfuller_result[0]}, p-value: {adfuller_result[1]}')\n",
    "print(f'KPSS Statistic: {kpss_result[0]}, p-value: {kpss_result[1]}')\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Gráfico series\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(7, 5), sharex=True)\n",
    "datos.plot(ax=axs[0], title='Serie original')\n",
    "datos_diff_1.plot(ax=axs[1], title='Diferenciación orden 1')\n",
    "datos_diff_2.plot(ax=axs[2], title='Diferenciación orden 2');\n",
    "# plt.savefig('serieDif.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95120d40",
   "metadata": {},
   "source": [
    "El p-value obtenido tras la primera diferenciación es estadísticamente significativo acorde al umbral reconocido y aceptado de 0.05. Por lo tanto, la selección más adecuada para el parámetro ARIMA $d$ es 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3b866",
   "metadata": {},
   "source": [
    "# Análisis de autocorrelación\n",
    "\n",
    "El gráfico de la función de autocorrelación ( Autocorrelation Function ACF) y la función de autocorrelación parcial (Partial Autocorrelation Function (PACF)) de la serie de tiempo proporciona información útil sobre los posibles valores adecuados de $p$ y $q$\n",
    ". La ACF ayuda a identificar el valor de $q$ (retardos en la parte de media móvil), mientras que la PACF ayuda a identificar el valor de $p$ (retardos en la parte autorregresiva)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf595d",
   "metadata": {},
   "source": [
    "## Función de autocorrelación (ACF)\n",
    "\n",
    "La ACF calcula la correlación entre una serie temporal y sus valores retardados (lags). En el contexto de la modelización ARIMA, una caída brusca de la ACF después de unos pocos retardos indica que los datos tienen un orden autorregresivo finito. El retardo en el que cae la **ACF** proporciona una **estimación** del valor de $q$\n",
    " . Si el ACF muestra un patrón sinusoidal o sinusoidal amortiguado, sugiere la presencia de estacionalidad y requiere la consideración de órdenes estacionales además de órdenes no estacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a61252",
   "metadata": {},
   "source": [
    "## Función de autocorrelación parcial (PACF)\n",
    "\n",
    "La PACF mide la correlación entre un valor retardado (lag) y el valor actual de la serie temporal, teniendo en cuenta el efecto de los retardos intermedios. En el contexto de la modelización ARIMA, si la PACF se corta bruscamente después de un determinado retardo, mientras que los valores restantes están dentro del intervalo de confianza, sugiere un modelo AR de ese orden. El desfase en el que se corta el **PACF** da una idea del valor de $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de autocorrelación para la serie original y la serie diferenciada\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(7, 4), sharex=True)\n",
    "plot_acf(datos, ax=axs[0], lags=50, alpha=0.05)\n",
    "axs[0].set_title('Autocorrelación serie original')\n",
    "plot_acf(datos_diff_1, ax=axs[1], lags=50, alpha=0.05)\n",
    "axs[1].set_title('Autocorrelación serie diferenciada (order=1)');\n",
    "# plt.savefig('AutocorrSerie.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf59619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelación parcial para la serie original y la serie diferenciada\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(7, 3), sharex=True)\n",
    "plot_pacf(datos, ax=axs[0], lags=50, alpha=0.05)\n",
    "axs[0].set_title('Autocorrelación parcial serie original')\n",
    "plot_pacf(datos_diff_1, ax=axs[1], lags=50, alpha=0.05)\n",
    "axs[1].set_title('Autocorrelación parcial serie diferenciada (order=1)');\n",
    "plt.tight_layout();\n",
    "# plt.savefig('AutocorrParc.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602d447",
   "metadata": {},
   "source": [
    "Acorde a la función de autocorrelación, el valor óptimo para el parámetro  $p$\n",
    "  es 0. Sin embargo, se va a asignar un valor de 1 para proporcionar un componente autorregresivo al modelo. En cuanto al componente  $q$\n",
    " , la función de autocorrelación parcial sugiere un valor de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea65504",
   "metadata": {},
   "source": [
    "# Descomposición de series temporales\n",
    "\n",
    "La descomposición de series temporales consiste en descomponer la serie temporal original en sus componentes fundamentales: la tendencia, la estacionalidad y los residuos. Esta descomposición puede llevarse a cabo de manera aditiva o multiplicativa. Al combinar la descomposición de las series temporales con el análisis de la ACF y la PACF, se obtiene una descripción bastante completa con la que comprender la estructura subyacente de los datos y acotar el valor los parámetros ARIMA más apropiados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88738ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Descomposición de la serie original y la serie diferenciada\n",
    "# ==============================================================================\n",
    "res_decompose = seasonal_decompose(datos, model='additive', extrapolate_trend='freq')\n",
    "res_descompose_diff_2 = seasonal_decompose(datos_diff_1, model='additive', extrapolate_trend='freq')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(9, 6), sharex=True)\n",
    "res_decompose.observed.plot(ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Serie original')\n",
    "res_decompose.trend.plot(ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Tendencia')\n",
    "res_decompose.seasonal.plot(ax=axs[2, 0])\n",
    "axs[2, 0].set_title('Estacionalidad')\n",
    "res_decompose.resid.plot(ax=axs[3, 0])\n",
    "axs[3, 0].set_title('Residuos')\n",
    "res_descompose_diff_2.observed.plot(ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Series diferenciadas (order=1)')\n",
    "res_descompose_diff_2.trend.plot(ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Tendencia')\n",
    "res_descompose_diff_2.seasonal.plot(ax=axs[2, 1])\n",
    "axs[2, 1].set_title('Estacionalidad')\n",
    "res_descompose_diff_2.resid.plot(ax=axs[3, 1])\n",
    "axs[3, 1].set_title('Residuos')\n",
    "fig.suptitle('Descomposición de la serie original vs serie diferenciada', fontsize=14)\n",
    "fig.tight_layout();\n",
    "# plt.savefig('SerieDescom.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1017e",
   "metadata": {},
   "source": [
    "El patrón recurrente cada 12 meses sugiere una estacionalidad anual, probablemente influenciada por factores vacacionales. El gráfico de ACF respalda aún más la presencia de esta estacionalidad, ya que se observan picos significativos en los lags correspondientes a los intervalos de 12 meses, confirmando la idea de patrones recurrentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99002891",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Basandose en los resultados del análisis exploratorio, utilizar una combinación de diferenciación de primer orden y diferenciación estacional puede ser el enfoque más apropiado. La diferenciación de primer orden es efectiva para capturar las transiciones entre observaciones y resaltar las fluctuaciones a corto plazo. Al mismo tiempo, la diferenciación estacional, que abarca un período de 12 meses y representa el cambio de un año a otro, captura de manera efectiva los patrones cíclicos inherentes en los datos. Este enfoque nos permite lograr la estacionariedad necesaria para el proceso de modelado ARIMA subsiguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferenciación de orden 1 combinada con diferenciación estacional\n",
    "# ==============================================================================\n",
    "datos_diff_1_12 = datos_train.diff().diff(12).dropna()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "adfuller_result = adfuller(datos_diff_1_12)\n",
    "print(f'ADF Statistic: {adfuller_result[0]}, p-value: {adfuller_result[1]}')\n",
    "kpss_result = kpss(datos_diff_1_12)\n",
    "print(f'KPSS Statistic: {kpss_result[0]}, p-value: {kpss_result[1]}')\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf285ade",
   "metadata": {},
   "source": [
    "# Modelo ARIMA-SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e22b5",
   "metadata": {},
   "source": [
    "## Usando Statsmodels\n",
    "\n",
    "Aquí se diferencia entre el proceso de definir un modelo y entrenarlo. \n",
    "\n",
    "Primero se define el modelo, incluyendo los parámetros configurables y el conjunto de datos de entrenamiento.\n",
    "\n",
    "Al usar el **fit**,En lugar de modificar el objeto modelo, statsmodels crea un nuevo objeto SARIMAXResults. Este objeto no solo encapsula detalles esenciales como los residuos y los parámetros aprendidos, sino que también proporciona las herramientas necesarias para generar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SARIMAX con statsmodels.Sarimax\n",
    "# ==============================================================================\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message='Non-invertible|Non-stationary')\n",
    "modelo = SARIMAX(endog = datos_train, order = (1, 1, 1), seasonal_order = (1, 1, 1, 12))\n",
    "modelo_res = modelo.fit(disp=0)\n",
    "warnings.filterwarnings(\"default\")\n",
    "modelo_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f937133",
   "metadata": {},
   "source": [
    "El resumen del modelo muestra mucha información sobre el proceso de ajuste:\n",
    "\n",
    "- Estadísticas de Ajuste del Modelo: Esta parte incluye varias estadísticas que ayudan a evaluar qué tan bien el modelo se ajusta a los datos observados:\n",
    "\n",
    "     - Log-Likelihood (Logaritmo de la Verosimilitud): Una medida de qué tan bien el modelo explica los datos observados, donde valores más negativos indican un ajuste deficiente a los datos y valores más cercanos a cero indican un mejor ajuste.\n",
    "  \n",
    "  - AIC (Criterio de Información de Akaike): Una métrica de bondad de ajuste que equilibra el ajuste del modelo con su complejidad. Cuanto menor el valor de AIC mejor es el modelo.\n",
    "  \n",
    "   - BIC (Criterio de Información Bayesiano): Similar al AIC, pero penaliza más la complejidad del modelo. Al igual que con el AIC, valores más bajos de BIC indican un mejor ajuste.\n",
    "   \n",
    "   - HQIC (Criterio de Información de Hannan-Quinn): Otro criterio de selección de modelo, similar al AIC y al BIC.\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d0ccc",
   "metadata": {},
   "source": [
    "- Coeficientes: Esta tabla lista los coeficientes estimados para los parámetros del modelo. Incluye tanto los parámetros autoregresivos (AR) como los parámetros de media móvil (MA), así como cualquier variable exógena si se incluyen en el modelo. También incluye los errores estándar asociados con los coeficientes estimados para indicar la incertidumbre de dichas estimaciones, sus p-values, que se utilizan para evaluar la significancia de cada coeficiente, y el intervalo de confianza del 95%.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8516f4c",
   "metadata": {},
   "source": [
    "- Diagnósticos del modelo: Esta sección proporciona información sobre los residuos. Las diferencias entre los valores observados (valores de entrenamiento) y los valores predichos por el modelo.\n",
    "\n",
    "  - Prueba Ljung-Box: Una prueba de autocorrelación en los residuos.\n",
    "\n",
    "  - Prueba de Jarque-Bera: Una prueba de normalidad de los residuos.\n",
    "\n",
    "  - Asimetría y curtosis: Medidas de la forma de la distribución de los residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción\n",
    "# ==============================================================================\n",
    "predicciones_statsmodels = modelo_res.get_forecast(steps=len(datos_test)).predicted_mean\n",
    "predicciones_statsmodels.name = 'predicciones_statsmodels'\n",
    "display(predicciones_statsmodels.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8c4f5",
   "metadata": {},
   "source": [
    "## Usando Skforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29544329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SARIMAX con skforecast.Sarimax\n",
    "# ==============================================================================\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message='Non-invertible|Non-stationary')\n",
    "modelo = Sarimax(order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "modelo.fit(y=datos_train)\n",
    "modelo.summary()\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción\n",
    "# ==============================================================================\n",
    "predicciones_skforecast = modelo.predict(steps=len(datos_test))\n",
    "display(predicciones_skforecast.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1b70b",
   "metadata": {},
   "source": [
    "Notar que las salidas de Skforecast son las mismas que de statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2baa04",
   "metadata": {},
   "source": [
    "## Usando pdmarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf849970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SARIMAX con pdmarima.Sarimax\n",
    "# ==============================================================================\n",
    "modelo = ARIMA(order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "modelo.fit(y=datos_train)\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediccion\n",
    "# ==============================================================================\n",
    "predicciones_pdmarima = modelo.predict(len(datos_test))\n",
    "predicciones_pdmarima.name = 'predicciones_pdmarima'\n",
    "display(predicciones_pdmarima.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones_statsmodels.plot(ax=ax, label='statsmodels')\n",
    "predicciones_skforecast.columns = ['skforecast']\n",
    "predicciones_skforecast.plot(ax=ax, label='skforecast')\n",
    "predicciones_pdmarima.plot(ax=ax, label='pmdarima')\n",
    "ax.set_title('Predictions with ARIMA models')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83c749",
   "metadata": {},
   "source": [
    "# ForecasterSarimax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fd0e5",
   "metadata": {},
   "source": [
    "Permite entrenar y validar modelos ARIMA y SARIMAX utilizando la API de skforecast.\n",
    "\n",
    "Dado que ForecasterSarimax sigue la misma API que los otros Forecasters disponibles en la librería, es muy fácil hacer una comparación robusta del rendimiento de modelos ARIMA-SARIMAX frente a otros modelos de machine learning como Random Forest or Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2925b",
   "metadata": {},
   "source": [
    "# Entrenamiento - Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d0af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo ARIMA con ForecasterSarimax y skforecast Sarimax\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "             )\n",
    "forecaster.fit(y=datos_train, suppress_warnings=True)\n",
    "\n",
    "# Predicción\n",
    "predicciones = forecaster.predict(steps=len(datos_test))\n",
    "predicciones.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6ac78",
   "metadata": {},
   "source": [
    "## Backtesting\n",
    "\n",
    "Ahora se muestra el uso de backtesting para evaluar el rendimiento del modelo SARIMAX al generar predicciones para los 12 meses siguientes en un plan anual. Se genera una previsión al final de cada mes de diciembre, pronosticando valores para los 12 meses siguientes.\n",
    "\n",
    "\n",
    "el proceso de backtesting consiste en evaluar el rendimiento de un modelo predictivo aplicándolo retrospectivamente a datos históricos. Por lo tanto, es un tipo especial de validación cruzada aplicada al periodo o periodos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(1, 1, 1, 12),\n",
    "                                maxiter=200\n",
    "                            )\n",
    "             )\n",
    "\n",
    "metrica, predicciones = backtesting_sarimax(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = datos,\n",
    "                            initial_train_size    = len(datos_train),\n",
    "                            fixed_train_size      = False,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_absolute_error',\n",
    "                            refit                 = True,\n",
    "                            n_jobs                = \"auto\",\n",
    "                            suppress_warnings_fit = True,\n",
    "                            verbose               = True,\n",
    "                            show_progress         = True\n",
    "                        )\n",
    "\n",
    "print(f\"Metrica (mean absolute error): {metrica}\")\n",
    "display(predicciones.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico predicciones de backtesting\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "datos.loc[fin_train:].plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax)\n",
    "ax.set_title('Predicciones de backtesting con un modelo SARIMA')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d24410",
   "metadata": {},
   "source": [
    "# Búsqueda de hiperparámetros p, d, q\n",
    "\n",
    "El análisis exploratorio ha reducido el espacio de búsqueda para los hiperparámetros óptimos del modelo. Sin embargo, para determinar definitivamente los valores más apropiados, es esencial utilizar métodos de búsqueda estratégicos. \n",
    "\n",
    "\n",
    "Entre estos métodos, dos enfoques ampliamente utilizados son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980efa4",
   "metadata": {},
   "source": [
    "- Criterios estadísticos: Las métricas de criterios de información, como el Criterio de Información de Akaike (AIC) o el Criterio de Información Bayesiano (BIC), utilizan diferentes penalizaciones sobre la estimación de máxima verosimilitud del modelo como medida de la bondad de ajuste. La ventaja de utilizar estas métricas es que se calculan únicamente con los datos de entrenamiento, lo que elimina la necesidad de realizar predicciones sobre nuevos datos. Como resultado, el proceso de optimización se acelera considerablemente. El conocido algoritmo Auto Arima utiliza este enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ff153",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "- Técnicas de validación: El uso de técnicas de validación, especialmente el backtesting, es otra estrategia efectiva. El backtesting consiste en evaluar el rendimiento del modelo utilizando datos históricos para simular las condiciones del mundo real. Esto ayuda a validar la eficacia de los hiperparámetros en diferentes escenarios, proporcionando una evaluación práctica de su viabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e2ee3",
   "metadata": {},
   "source": [
    "En el primer enfoque, los cálculos se basan únicamente en los datos de entrenamiento, lo que elimina la necesidad de realizar predicciones sobre nuevos datos. Esto hace que el proceso de optimización sea muy rápido. Sin embargo, es importante señalar que las métricas basadas en los criterios de información sólo miden la calidad relativa de los modelos. Esto significa que los modelos probados podrían ser deficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1369991",
   "metadata": {},
   "source": [
    "Por otro lado, el segundo enfoque -las técnicas de validación- suele requerir más tiempo, ya que el modelo debe entrenarse y luego evaluarse con nuevos datos. Sin embargo, los resultados generados suelen ser más robustos y las métricas derivadas pueden proporcionar información más profunda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcf9a0",
   "metadata": {},
   "source": [
    "### Ahora se optimizan los hiperparámetros con un conjunto de datos de validación, para una evaluación precisa del rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test\n",
    "# ======================================================================================\n",
    "fin_train = '1976-01-01 23:59:59'\n",
    "fin_val = '1984-01-01 23:59:59'\n",
    "print(\n",
    "    f\"Fechas entrenamiento : {datos.index.min()} --- {datos.loc[:fin_train].index.max()}  \"\n",
    "    f\"(n={len(datos.loc[:fin_train])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Fechas validacion    : {datos.loc[fin_train:].index.min()} --- {datos.loc[:fin_val].index.max()}  \"\n",
    "    f\"(n={len(datos.loc[fin_train:fin_val])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Fechas test          : {datos.loc[fin_val:].index.min()} --- {datos.index.max()}  \"\n",
    "    f\"(n={len(datos.loc[fin_val:])})\"\n",
    ")\n",
    "\n",
    "# Gráfico\n",
    "# ======================================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "datos.loc[:fin_train].plot(ax=ax, label='entrenamiento')\n",
    "datos.loc[fin_train:fin_val].plot(ax=ax, label='validación')\n",
    "datos.loc[fin_val:].plot(ax=ax, label='test')\n",
    "ax.set_title('Consumo mensual combustible España')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9965631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search basado en backtesting\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(\n",
    "                                order=(1, 1, 1), # Placeholder replaced in the grid search\n",
    "                                maxiter=500\n",
    "                            )\n",
    "             )\n",
    "\n",
    "param_grid = {\n",
    "    'order': [(0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (2, 1, 1)],\n",
    "    'seasonal_order': [(0, 0, 0, 0), (0, 1, 0, 12), (1, 1, 1, 12)],\n",
    "    'trend': [None, 'n', 'c']\n",
    "}\n",
    "\n",
    "resultados_grid = grid_search_sarimax(\n",
    "                        forecaster            = forecaster,\n",
    "                        y                     = datos.loc[:fin_val],\n",
    "                        param_grid            = param_grid,\n",
    "                        steps                 = 12,\n",
    "                        refit                 = True,\n",
    "                        metric                = 'mean_absolute_error',\n",
    "                        initial_train_size    = len(datos_train),\n",
    "                        fixed_train_size      = False,\n",
    "                        return_best           = False,\n",
    "                        n_jobs                = 'auto',\n",
    "                        suppress_warnings_fit = True,\n",
    "                        verbose               = False,\n",
    "                        show_progress         = True\n",
    "                   )\n",
    "\n",
    "resultados_grid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd66da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto arima: seleccion basada en AIC\n",
    "# ==============================================================================\n",
    "modelo = auto_arima(\n",
    "            y                 = datos.loc[:fin_val],\n",
    "            start_p           = 0,\n",
    "            start_q           = 0,\n",
    "            max_p             = 3,\n",
    "            max_q             = 3,\n",
    "            seasonal          = True,\n",
    "            test              = 'adf',\n",
    "            m                 = 12, # periodicidad de la estacionalidad\n",
    "            d                 = None, # El algoritmo determina 'd'\n",
    "            D                 = None, # El algoritmo determina 'D'\n",
    "            trace             = True,\n",
    "            error_action      = 'ignore',\n",
    "            suppress_warnings = True,\n",
    "            stepwise          = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7022612",
   "metadata": {},
   "source": [
    "Puede ser de interés capturar la traza generada por la función *auto_arima* para permitir una exploración más exhaustiva de los resultados. La implementación actual imprime los resultados, pero es posible capturarlos y almacenarlos en un marco de datos estructurado de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02948c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture auto_arima trace in a pandas datosframe\n",
    "# ==============================================================================\n",
    "buffer = StringIO()\n",
    "with contextlib.redirect_stdout(buffer):\n",
    "    auto_arima(\n",
    "            y                 = datos.loc[:fin_val],\n",
    "            start_p           = 0,\n",
    "            start_q           = 0,\n",
    "            max_p             = 3,\n",
    "            max_q             = 3,\n",
    "            seasonal          = True,\n",
    "            test              = 'adf',\n",
    "            m                 = 12, # periodicidad de la estacionalidad\n",
    "            d                 = None, # El algoritmo determina 'd'\n",
    "            D                 = None, # El algoritmo determina 'D'\n",
    "            trace             = True,\n",
    "            error_action      = 'ignore',\n",
    "            suppress_warnings = True,\n",
    "            stepwise          = True\n",
    "        )\n",
    "trace_autoarima = buffer.getvalue()\n",
    "pattern = r'ARIMA\\((\\d+),(\\d+),(\\d+)\\)\\((\\d+),(\\d+),(\\d+)\\)\\[(\\d+)\\]\\s+(intercept)?\\s+:\\s+AIC=([\\d\\.]+), Time=([\\d\\.]+) sec'\n",
    "matches = re.findall(pattern, trace_autoarima)\n",
    "results = pd.DataFrame(matches, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'm', 'intercept', 'AIC', 'Time'])\n",
    "results['order'] = results[['p', 'd', 'q']].apply(lambda x: f\"({x[0]},{x[1]},{x[2]})\", axis=1)\n",
    "results['seasonal_order'] = results[['P', 'D', 'Q', 'm']].apply(lambda x: f\"({x[0]},{x[1]},{x[2]},{x[3]})\", axis=1)\n",
    "results = results[['order', 'seasonal_order', 'intercept', 'AIC', 'Time']]\n",
    "results.sort_values(by='AIC').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389c68c",
   "metadata": {},
   "source": [
    "Se comparan los dos modelos candidatos: el seleccionado por grid_search_sarimax basado en backtesting con un error absoluto medio, y el seleccionado por auto_arima basado en el AIC, al realizar predicciones para los próximos tres años en intervalos de 12 meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1389072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones de backtesting con el mejor modelo según el grid search\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(order=(0, 1, 1), seasonal_order=(1, 1, 1, 12), maxiter=500),\n",
    "             )\n",
    "\n",
    "metrica_m1, predicciones_m1 = backtesting_sarimax(\n",
    "                                forecaster            = forecaster,\n",
    "                                y                     = datos,\n",
    "                                initial_train_size    = len(datos.loc[:fin_val]),\n",
    "                                steps                 = 12,\n",
    "                                metric                = 'mean_absolute_error',\n",
    "                                refit                 = True,\n",
    "                                n_jobs                = \"auto\",\n",
    "                                suppress_warnings_fit = True,\n",
    "                                verbose               = False,\n",
    "                                show_progress         = True\n",
    "                            )\n",
    "\n",
    "# Predicciones de backtesting con el mejor modelo según auto arima\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(order=(1, 1, 1), seasonal_order=(0, 1, 1, 12), maxiter=500),\n",
    "             )\n",
    "\n",
    "metrica_m2, predicciones_m2 = backtesting_sarimax(\n",
    "                                forecaster            = forecaster,\n",
    "                                y                     = datos,\n",
    "                                initial_train_size    = len(datos.loc[:fin_val]),\n",
    "                                steps                 = 12,\n",
    "                                metric                = 'mean_absolute_error',\n",
    "                                refit                 = True,\n",
    "                                n_jobs                = \"auto\",\n",
    "                                suppress_warnings_fit = True,\n",
    "                                verbose               = False,\n",
    "                                show_progress         = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ded51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de métricas\n",
    "# ==============================================================================\n",
    "print(f\"Metrica (mean absolute error) del modelo grid search : {metrica_m1}\")\n",
    "print(f\"Metric (mean_absolute_error) del modelo auto arima   : {metrica_m2}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "datos.loc[fin_val:].plot(ax=ax, label='test')\n",
    "predicciones_m1 = predicciones_m1.rename(columns={'pred': 'grid search'})\n",
    "predicciones_m2 = predicciones_m2.rename(columns={'pred': 'autoarima'})\n",
    "predicciones_m1.plot(ax=ax)\n",
    "predicciones_m2.plot(ax=ax)\n",
    "ax.set_title('Predicciones de backtesting con un modelo SARIMA')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f19ff6",
   "metadata": {},
   "source": [
    "La configuración SARIMAX identificada mediante la técnica de grid search (basada en backtesting con error medio absoluto) ofrece resultados ligeramente mejores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31145688",
   "metadata": {},
   "source": [
    "# Variables exógenas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bfee2",
   "metadata": {},
   "source": [
    "el uso de ARIMA-SARIMAX de statmodels nos entrega la capacidad de integrar variables exógenas junto a la serie de tiempo principal que se estudia.\n",
    "\n",
    "El requisito para incluir las variables exógenas, es que se debe conocer el valor de la variable también durante el período de predicción. \n",
    "\n",
    "*\"Para garantizar que sus efectos se tienen en cuenta con precisión, es crucial incluir estas variables tanto en la fase de entrenamiento como en la de predicción. Esto ayudará a optimizar la precisión de las previsiones y a proporcionar predicciones más fiables.''*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf91ace",
   "metadata": {},
   "source": [
    "# Usar un modelo ARIMA-SARIMAX ya entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e02ec",
   "metadata": {},
   "source": [
    "Realizar predicciones con un modelo ARIMA se complica cuando los datos del horizonte de previsión no siguen inmediatamente al último valor observado durante la fase de entrenamiento. Dado que la componente media movil (MA) utiliza como datos los errores asociados a los pronósticos anteriores\n",
    "\n",
    "Si esta predicción no está disponible, el error correspondiente permanece inaccesible. Por esta razón, en la mayoría de los casos, los modelos ARIMA se vuelven a entrenar cada vez que se necesitan hacer predicciones.\n",
    "\n",
    "Un enfoque intermedio es alimentar al modelo con datos desde la última observación de entrenamiento hasta el inicio de la fase de predicción. Por ejemplo, supóngase que un modelo se entrenó hace 20 días con datos diarios de los últimos tres años. Al generar nuevas predicciones, sólo se necesitarían los 20 valores más recientes, en lugar del conjunto de datos históricos completo .\n",
    "\n",
    "Integrar nuevos datos en el modelo puede ser complejo, la clase ForecasterSarimax automatiza el proceso mediante el argumento last_window de su método predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78766ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División datos Train - Last window\n",
    "# ==============================================================================\n",
    "fin_train = '1980-01-01 23:59:59'\n",
    "                       \n",
    "print(\n",
    "    f\"Fechas entrenamiento : {datos.index.min()} --- {datos.loc[:fin_train].index.max()}  \"\n",
    "    f\"(n={len(datos.loc[:fin_train])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Fechas Last window  : {datos.loc[fin_train:].index.min()} --- {datos.index.max()}  \"\n",
    "    f\"(n={len(datos.loc[fin_train:])})\"\n",
    ")\n",
    "\n",
    "# Gráfico\n",
    "# ======================================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "datos.loc[:fin_train].plot(ax=ax, label='entrenamiento')\n",
    "datos.loc[fin_train:].plot(ax=ax, label='last window')\n",
    "ax.set_title('Consumo mensual combustible España')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d27ef7",
   "metadata": {},
   "source": [
    "El Forecaster se entrena utilizando datos hasta el '1980-01-01' y luego utilizará la información restante como última ventana de observaciones para generar nuevas predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3061cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo con datos desde 1969-01-01 hasta 1980-01-01\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterSarimax(\n",
    "                 regressor=Sarimax(order=(0, 1, 1), seasonal_order=(1, 1, 1, 12), maxiter=500),\n",
    "             )\n",
    "forecaster.fit(y=datos.loc[:fin_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción utilizando last window\n",
    "# ==============================================================================\n",
    "predicciones = forecaster.predict(\n",
    "                  steps       = 12,\n",
    "                  last_window = datos.loc[fin_train:]\n",
    "              )\n",
    "predicciones.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "# ======================================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "datos.loc[:fin_train].plot(ax=ax, label='entrenamiento')\n",
    "datos.loc[fin_train:].plot(ax=ax, label='last window')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.set_title('Consumo mensual combustible España')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
